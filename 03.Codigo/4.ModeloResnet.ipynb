{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from ResNet import resnet\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(log):\n",
    "  val_loss = log.history['val_loss']\n",
    "  val_acc = log.history['val_accuracy']\n",
    "      \n",
    "  fig, axes = plt.subplots(1, 2, figsize=(14,4))\n",
    "  ax1, ax2 = axes\n",
    "  ax1.plot(log.history['loss'], label='train')\n",
    "  ax1.plot(val_loss, label='test')\n",
    "  ax1.set_xlabel('epoch'); ax1.set_ylabel('loss')\n",
    "  ax2.plot(log.history['accuracy'], label='train')\n",
    "  ax2.plot(val_acc, label='test')\n",
    "  ax2.set_xlabel('epoch'); ax2.set_ylabel('accuracy')\n",
    "  for ax in axes: ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_path = \"models/model\"\n",
    "\n",
    "monitor = \"val_accuracy\"\n",
    "\n",
    "mode = \"max\"\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_path, monitor=monitor, verbose=1, save_best_only=True, save_weights_only=True, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath(os.getcwd())+'\\\\resultados\\\\'\n",
    "\n",
    "# Guardamos la configuracion del NumPy np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# Modificamos un parametro del np.load por defecto que no permitia realizar la descarga\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "train_data = np.load(path+'train_data.npy')\n",
    "train_labels = np.load(path+'train_labels.npy')\n",
    "test_data = np.load(path+'test_data.npy')\n",
    "test_labels = np.load(path+'test_labels.npy')\n",
    "labels = np.load(path+'labels.npy')\n",
    "\n",
    "# Restauramo np.load para su futuro uso regular\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "nb_classes = 200\n",
    "nb_epoch = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 64, 64\n",
    "# The images are RGB\n",
    "img_channels = 3\n",
    "\n",
    "input_shape = (img_rows, img_cols, img_channels)\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "X_train = train_data\n",
    "Y_train = train_labels\n",
    "X_test = test_data\n",
    "Y_test = test_labels\n",
    "del train_data\n",
    "del train_labels\n",
    "del test_data\n",
    "del test_labels\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# subtract mean and normalize\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_train /= 128.\n",
    "X_test /= 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "\n",
    "dataset_train = dataset_train.shuffle(buffer_size=100).batch(bs).prefetch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "\n",
    "dataset_test = dataset_test.batch(bs).prefetch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAVID\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = resnet.ResNet.build(64, 64, 3, nb_classes, (3, 4, 6),\n",
    "\t\t(64, 128, 256, 512), reg = 0.0005, dataset = \"tiny_imagenet\")\n",
    "opt = SGD(lr = 1e-1, momentum = 0.9, nesterov = True)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 4.8963 - accuracy: 0.1036\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12680, saving model to models\\model\n",
      "782/782 [==============================] - 3518s 4s/step - loss: 4.8963 - accuracy: 0.1036 - val_loss: 4.6566 - val_accuracy: 0.1268\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 4.0420 - accuracy: 0.2168\n",
      "Epoch 00002: val_accuracy improved from 0.12680 to 0.20040, saving model to models\\model\n",
      "782/782 [==============================] - 3535s 5s/step - loss: 4.0420 - accuracy: 0.2168 - val_loss: 4.2146 - val_accuracy: 0.2004\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.7016 - accuracy: 0.2769\n",
      "Epoch 00003: val_accuracy improved from 0.20040 to 0.23370, saving model to models\\model\n",
      "782/782 [==============================] - 3510s 4s/step - loss: 3.7016 - accuracy: 0.2769 - val_loss: 4.0280 - val_accuracy: 0.2337\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.4938 - accuracy: 0.3180\n",
      "Epoch 00004: val_accuracy did not improve from 0.23370\n",
      "782/782 [==============================] - 3510s 4s/step - loss: 3.4938 - accuracy: 0.3180 - val_loss: 4.2460 - val_accuracy: 0.2140\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.3502 - accuracy: 0.3509\n",
      "Epoch 00005: val_accuracy improved from 0.23370 to 0.26210, saving model to models\\model\n",
      "782/782 [==============================] - 3562s 5s/step - loss: 3.3502 - accuracy: 0.3509 - val_loss: 3.9138 - val_accuracy: 0.2621\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.2451 - accuracy: 0.3761\n",
      "Epoch 00006: val_accuracy improved from 0.26210 to 0.26490, saving model to models\\model\n",
      "782/782 [==============================] - 3521s 5s/step - loss: 3.2451 - accuracy: 0.3761 - val_loss: 3.9496 - val_accuracy: 0.2649\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.1746 - accuracy: 0.3987\n",
      "Epoch 00007: val_accuracy improved from 0.26490 to 0.27320, saving model to models\\model\n",
      "782/782 [==============================] - 3528s 5s/step - loss: 3.1746 - accuracy: 0.3987 - val_loss: 4.0025 - val_accuracy: 0.2732\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.1238 - accuracy: 0.4203\n",
      "Epoch 00008: val_accuracy improved from 0.27320 to 0.29840, saving model to models\\model\n",
      "782/782 [==============================] - 3528s 5s/step - loss: 3.1238 - accuracy: 0.4203 - val_loss: 3.9020 - val_accuracy: 0.2984\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0973 - accuracy: 0.4370\n",
      "Epoch 00009: val_accuracy did not improve from 0.29840\n",
      "782/782 [==============================] - 3530s 5s/step - loss: 3.0973 - accuracy: 0.4370 - val_loss: 4.0841 - val_accuracy: 0.2927\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0812 - accuracy: 0.4514\n",
      "Epoch 00010: val_accuracy improved from 0.29840 to 0.30470, saving model to models\\model\n",
      "782/782 [==============================] - 3471s 4s/step - loss: 3.0812 - accuracy: 0.4514 - val_loss: 4.0680 - val_accuracy: 0.3047\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0745 - accuracy: 0.4638\n",
      "Epoch 00011: val_accuracy did not improve from 0.30470\n",
      "782/782 [==============================] - 3174s 4s/step - loss: 3.0745 - accuracy: 0.4638 - val_loss: 4.6032 - val_accuracy: 0.2518\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0705 - accuracy: 0.4756\n",
      "Epoch 00012: val_accuracy improved from 0.30470 to 0.32570, saving model to models\\model\n",
      "782/782 [==============================] - 3284s 4s/step - loss: 3.0705 - accuracy: 0.4756 - val_loss: 4.0387 - val_accuracy: 0.3257\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0726 - accuracy: 0.4871\n",
      "Epoch 00013: val_accuracy did not improve from 0.32570\n",
      "782/782 [==============================] - 3531s 5s/step - loss: 3.0726 - accuracy: 0.4871 - val_loss: 4.2952 - val_accuracy: 0.3023\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0796 - accuracy: 0.4946\n",
      "Epoch 00014: val_accuracy did not improve from 0.32570\n",
      "782/782 [==============================] - 3568s 5s/step - loss: 3.0796 - accuracy: 0.4946 - val_loss: 4.3313 - val_accuracy: 0.3129\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0801 - accuracy: 0.5048\n",
      "Epoch 00015: val_accuracy did not improve from 0.32570\n",
      "782/782 [==============================] - 3468s 4s/step - loss: 3.0801 - accuracy: 0.5048 - val_loss: 4.7786 - val_accuracy: 0.2565\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0869 - accuracy: 0.5140\n",
      "Epoch 00016: val_accuracy did not improve from 0.32570\n",
      "782/782 [==============================] - 3190s 4s/step - loss: 3.0869 - accuracy: 0.5140 - val_loss: 4.9087 - val_accuracy: 0.2672\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0921 - accuracy: 0.5188\n",
      "Epoch 00017: val_accuracy did not improve from 0.32570\n",
      "782/782 [==============================] - 3319s 4s/step - loss: 3.0921 - accuracy: 0.5188 - val_loss: 4.6194 - val_accuracy: 0.3071\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.0979 - accuracy: 0.5270\n",
      "Epoch 00018: val_accuracy improved from 0.32570 to 0.32880, saving model to models\\model\n",
      "782/782 [==============================] - 3394s 4s/step - loss: 3.0979 - accuracy: 0.5270 - val_loss: 4.4222 - val_accuracy: 0.3288\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.1136 - accuracy: 0.5312\n",
      "Epoch 00019: val_accuracy did not improve from 0.32880\n",
      "782/782 [==============================] - 3250s 4s/step - loss: 3.1136 - accuracy: 0.5312 - val_loss: 4.7789 - val_accuracy: 0.2894\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - ETA: 0s - loss: 3.1185 - accuracy: 0.5376\n",
      "Epoch 00020: val_accuracy improved from 0.32880 to 0.33020, saving model to models\\model\n",
      "782/782 [==============================] - 3364s 4s/step - loss: 3.1185 - accuracy: 0.5376 - val_loss: 4.4953 - val_accuracy: 0.3302\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "history = model.fit(dataset_train, batch_size=bs, epochs=epochs, validation_data=dataset_test, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAVID\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "epochs_passed = 20\n",
    "model.save_weights( 'models/model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )\n",
    "model.save( 'models/custom_resent50_model.h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "epochs_passed = 20\n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "model = load_model( 'models/custom_resent50_model.h5')\n",
    "model.load_weights( 'models/model_weights_Img_aug_after_%s_epoch.h5' % epochs_passed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 10 # epoch 21-30\n",
    "# Fit the model on the batches generated by datagen.flow()."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e076b56c7058fe20ecfcc311ef0c7a4c55ddb853ffaea1265e112a7471bdb30"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
